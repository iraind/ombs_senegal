{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *\n",
    "from fastcore.basics import patch\n",
    "from pathlib import Path\n",
    "from math import factorial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will first open the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = Path(\"../testing_data\")\n",
    "\n",
    "data = pd.read_csv(\n",
    "    DATA_PATH/'hydro_example.csv', \n",
    "    usecols=['time', 'smoothed_rain', 'Q_mgb', 'Q_obs'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature generator\n",
    "> Feature generator that uses a sliding window of n previous timesteps and polynomial features to predict the next value, enabling learning of temporal patterns and non-linear relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class FeatureAndTargetGenerator:\n",
    "    \"\"\"\n",
    "    Transforms time series data into feature matrices suitable for machine learning models.\n",
    "    Creates lagged features using a sliding window and optionally generates polynomial features\n",
    "    to capture non-linear relationships between variables. It also creates a target vector for\n",
    "    the number of timesteps to predict.\n",
    "    \"\"\"\n",
    "    def __init__(self, \n",
    "                 context_len: int = 10, # number of previous timesteps to use as features\n",
    "                 target_len: int = 10, # number of timesteps to predict\n",
    "                 poly_degree: int = 1 # degree of polynomial features\n",
    "                 ):\n",
    "        self.context_len = context_len\n",
    "        self.target_len = target_len\n",
    "        self.poly_features = PolynomialFeatures(degree=poly_degree)\n",
    "        \n",
    "    def generate(self, df: pd.DataFrame, x_col: list[str], y_col: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\" Generates a feature matrix and target vector from the input data. \"\"\"\n",
    "        X, y = df[x_col], df[y_col]\n",
    "        if 1 < self.poly_features.degree:\n",
    "            X = pd.DataFrame(self.poly_features.fit_transform(X), index=X.index)\n",
    "        X, y = self._generate_sliding_window_data(X, y)\n",
    "        return X, y\n",
    "\n",
    "\n",
    "    def _generate_sliding_window_data(self, X: pd.DataFrame, y: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n",
    "        \"\"\"\n",
    "        Creates a feature matrix by combining multiple input variables and their lagged values.\n",
    "        For each time step t, takes values from t-context_len to t for each input variable\n",
    "        and combines them into a single feature vector. The target values are taken from t+1 to t+target_len.\n",
    "        This allows the model to learn patterns across multiple timesteps and predict multiple steps ahead.\n",
    "        \"\"\"\n",
    "        features = []\n",
    "        targets = []\n",
    "        \n",
    "        for i in range(len(X) - self.context_len - self.target_len):\n",
    "            row_features = X.iloc[i:i + self.context_len]\n",
    "            features.append(row_features.values.reshape(-1))\n",
    "            row_targets = y.iloc[i + self.context_len: i + self.context_len + self.target_len]\n",
    "            targets.append(row_targets.values.reshape(-1))\n",
    "\n",
    "        features = pd.DataFrame(\n",
    "            index=X.index[self.context_len - 1:len(X) - self.target_len - 1],\n",
    "              data=features)\n",
    "        targets = pd.DataFrame(\n",
    "            index=y.index[self.context_len - 1:len(X) - self.target_len - 1],\n",
    "            data=targets,\n",
    "            columns=[f\"t+{i+1}\" for i in range(0, self.target_len)])\n",
    "        return features, targets\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to create an instance of the generator setting the context and the target length and the polynomial degree."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator = FeatureAndTargetGenerator(context_len=1, target_len=2, poly_degree=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we can generate the feature and target matrixes as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_doc(FeatureAndTargetGenerator.generate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col, y_col = ['smoothed_rain','Q_mgb'], ['Q_obs']\n",
    "data_x, data_y = generator.generate(data, x_col=x_col, y_col=y_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The generated data will look as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_x.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_y.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "gen_test = FeatureAndTargetGenerator(context_len=3, target_len=2, poly_degree=1)\n",
    "test_x, test_y = gen_test.generate(data, x_col=x_col, y_col=y_col)\n",
    "\n",
    "# Test the shape and the index matching for multistep features and prediction\n",
    "def test_target_shape(gen_test, test_y):\n",
    "    assert test_y.shape[1] == gen_test.target_len, f\"Expected {gen_test.target_len} target columns but got {test_y.shape[1]}\"\n",
    "    assert all(f't+{i+1}' in test_y.columns for i in range(gen_test.target_len)), \"Target columns not properly named\"\n",
    "\n",
    "def test_index_matching(test_x, test_y):\n",
    "    assert test_x.index.equals(test_y.index), \"Feature and target indices do not match\"\n",
    "    assert test_x.shape[0] == test_y.shape[0], f\"Feature and target row counts don't match: {test_x.shape[0]} vs {test_y.shape[0]}\"\n",
    "\n",
    "def test_sample_count(gen_test, test_x, data):\n",
    "    if not test_x.shape[0] == data.shape[0] - gen_test.context_len - gen_test.target_len:\n",
    "        raise ValueError(f\"Expected {data.shape[0] - gen_test.context_len - gen_test.target_len} samples but got {test_x.shape[0]}\")\n",
    "\n",
    "def test_values(test_x, test_y, data, gen_test, x_col, y_col):\n",
    "    if not all(test_x.iloc[5].values == data.iloc[5:5+gen_test.context_len][x_col].values.reshape(-1)):\n",
    "        raise ValueError(\"Feature values do not match expected values from source data\")\n",
    "    if not all(test_y.iloc[2].values == data.iloc[2+gen_test.context_len:2+gen_test.context_len+gen_test.target_len][y_col].values.reshape(-1)):\n",
    "        raise ValueError(\"Target values do not match expected values from source data\")\n",
    "\n",
    "test_target_shape(gen_test, test_y)\n",
    "test_index_matching(test_x, test_y)\n",
    "test_sample_count(gen_test, test_x, data)\n",
    "test_values(test_x, test_y, data, gen_test, x_col, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| test\n",
    "def test_polynomial_features(data, x_col, y_col):\n",
    "    def poly_terms(vars, deg): return (factorial(len(vars) +deg))/(factorial(len(vars))*factorial(deg))\n",
    "    \n",
    "    gen_test = FeatureAndTargetGenerator(context_len=2, target_len=2, poly_degree=3)\n",
    "    test_x, _ = gen_test.generate(data, x_col=x_col, y_col=y_col)\n",
    "    expected_cols = gen_test.context_len * poly_terms(x_col, gen_test.poly_features.degree)\n",
    "    if not test_x.shape[1] == expected_cols:\n",
    "        raise ValueError(f\"Expected {expected_cols} polynomial feature columns but got {test_x.shape[1]}\")\n",
    "    \n",
    "test_polynomial_features(data, x_col, y_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
