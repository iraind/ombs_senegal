# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/01_benchmark_model.ipynb.

# %% auto 0
__all__ = ['normalize', 'FeatureGenerator', 'SimpleRegressionModel', 'BenchmarkScores', 'plot_benchmark_scores']

# %% ../nbs/01_benchmark_model.ipynb 3
import numpy as np
import pandas as pd
import xarray as xr
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures

# %% ../nbs/01_benchmark_model.ipynb 6
def normalize(df):
    return (df - df.min()) / (df.max() - df.min())

# %% ../nbs/01_benchmark_model.ipynb 15
class FeatureGenerator:
    """
    Transforms time series data into feature matrices suitable for machine learning models.
    Creates lagged features using a sliding window and optionally generates polynomial features
    to capture non-linear relationships between variables.
    """
    def __init__(self, context_window: int = 10, target_window: int = 10, degree: int = 1):
        self.context_window = context_window
        self.target_window = target_window
        self.poly_features = PolynomialFeatures(degree=degree)
        
    def generate(self, df: pd.DataFrame, x_col: list[str], y_col: list[str]) -> tuple[pd.DataFrame, pd.DataFrame]:
        X, y = df[x_col], df[y_col]
        if 1 < self.poly_features.degree:
            X = pd.DataFrame(self.poly_features.fit_transform(X), index=X.index)
        X, y = self.generate_sliding_window_features(X, y)
        return X, y


    def generate_sliding_window_features(self, X: pd.DataFrame, y: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
        """
        Creates a feature matrix by combining multiple input variables and their lagged values.
        For each time step t, takes values from t-window to t for each input variable
        and combines them into a single feature vector. The target value is taken at time t.
        This allows the model to learn patterns across multiple timesteps.
        """
        features = []
        targets = []
        
        for i in range(len(X) - self.context_window - self.target_window):
            row_features = X.iloc[i:i + self.context_window]
            features.append(row_features.values.reshape(-1))
            row_targets = y.iloc[i + self.context_window: i + self.context_window + (self.target_window + 1)]
            targets.append(row_targets.values.reshape(-1))

        features = pd.DataFrame(index=X.index[self.context_window:len(X) - self.target_window], data=features)
        targets = pd.DataFrame(
            index=y.index[self.context_window:len(X) - self.target_window],
            data=targets,
            columns=[f"t+{i}" for i in range(0, self.target_window+1)])
        return features, targets
    


# %% ../nbs/01_benchmark_model.ipynb 18
class SimpleRegressionModel:
    def __init__(self):
        self.model = LinearRegression()
    
    def fit(self, X, y=None):
        self.model.fit(X, y)
        return self
    
    def predict(self, X):
        pred = self.model.predict(X)
        return pd.DataFrame(pred, index=X.index, columns=[f"t+{i}" for i in range(0, pred.shape[1])])

# %% ../nbs/01_benchmark_model.ipynb 22
class BenchmarkScores:
    """A class to compute and compare different error metrics between predictions and observations.
    
    This class provides a flexible way to compute multiple error metrics between predicted and observed values.
    New metrics can be easily added by implementing them as methods.
    The new metrics can then be used by passing their method names as strings to compute_scores().
    
    Example:
        ```python
        class CustomBenchmarkScores(BenchmarkScores):
        def mse(self, pred, obs):
            error = ((pred - obs)**2).mean(dim="time") 
            error.name = "mse"
            return error
            
        # Can then be used as:
        scores = compute_scores(pred, obs, metrics=["mae", "rmse", "mse"])
        ```
    """
    def __init__(self):
        pass

    def compute_scores(self, predictions: xr.DataArray, observations: xr.DataArray, metrics: list[str]):
        """Compute the scores for the predictions and observations."""
        scores = []
        for metric in metrics:
            scores.append(getattr(self, metric)(predictions, observations).to_dataset(name=metric))
        return xr.merge(scores)
    
    def mae(self, pred, obs):
        error = abs(pred - obs).mean(dim="time")
        error.name = "mae"
        return error

    def rmse(self, pred, obs):
        error = np.sqrt(((pred - obs)**2).mean(dim="time"))
        error.name = "rmse"
        return error
    
    def _compute_score(self, predictions: xr.Dataset, observations: xr.Dataset, metric: str):
        pass

    def find_nbest_scores(self, ds: xr.Dataset, n: int=2):
        """Given a dataset containing scores as variables,find the n best scores for each variable."""
        for metric in ds.data_vars:
            min_coords = self._find_nsmallest_index(ds[metric].to_series(), n)
            n_best_scores = ds.to_dataframe().reorder_levels(min_coords.names).loc[min_coords]
            return n_best_scores

    def _find_nsmallest_index(self, serie: pd.Series, n):
        """Find the n smallest values for each variable in a serie and return their index."""
        sorted = serie.sort_values()
        nsmallest_values = []
        for v in sorted.index.get_level_values("variable").unique():
            nsmallest_values.append(sorted.loc[[v]].head(n))
        nsmallest_values = pd.concat(nsmallest_values)
        return nsmallest_values.index

# %% ../nbs/01_benchmark_model.ipynb 25
def plot_benchmark_scores(
        df: pd.DataFrame, # Dataframe with polynomial degree and window as index and mae and mse as columns
        figsize: tuple=(8, 7), # Figure size in inches (width, height)
        fontsize: int=7, # Font size for annotations
        xlim: tuple=(None, None), # Tuple of (min, max) values for x-axis limits
        ylim: tuple=(None, None), # Tuple of (min, max) values for y-axis limits
        ):
    """Plot MAE vs MSE scores with degree and window annotations for model comparison"""
    fig, ax = plt.subplots(figsize=figsize)
    
    # Get unique time steps - expected format 't+N' where N is 0-10
    time_steps = []
    for col in df.index.get_level_values(0).unique():
        if isinstance(col, str) and col.startswith('t+'):
            time_steps.append(col)
    time_steps = sorted(time_steps, key=lambda x: int(x.split('+')[1]))
    
    # Create a colormap
    colors = plt.cm.viridis(np.linspace(0, 1, len(time_steps)))
    
    # Plot each time step with different color
    for t, color in zip(time_steps, colors):
        mask = df.index.get_level_values(0) == t
        df_t = df[mask]
        scatter = ax.scatter(df_t['mae'], df_t['rmse'], label=t, color=color)
        
        # Add annotations for each point
        for (_, deg, win), (mae, rmse) in zip(df_t.index, df_t[['mae', 'rmse']].values):
            ax.annotate(f'd={deg},w={win}', (mae, rmse), 
                       xytext=(5, 5), textcoords='offset points', 
                       fontsize=fontsize, color=color)

    ax.set(xlabel='MAE', ylabel='RMSE', 
           title='MAE vs RMSE for different degrees, windows and prediction horizons')
    ax.legend(title='Prediction horizon', bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.xlim(*xlim)
    plt.ylim(*ylim)
    plt.tight_layout()
    plt.show()
