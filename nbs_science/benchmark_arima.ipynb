{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ARIMA Modeling for Time Series Analysis\n",
    "\n",
    "This notebook explores the ARIMA model as predictor for the water flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import numpy as np\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from pmdarima import auto_arima\n",
    "from ombs_senegal.season import SeasonalityHandler\n",
    "# from statsmodels.stats.diagnostic import acf\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from datetime import datetime, timedelta\n",
    "from pathlib import Path\n",
    "from ombs_senegal.benchmark_model import BenchmarkScores\n",
    "\n",
    "# Set style for better visualizations\n",
    "#plt.style.use('seaborn')\n",
    "sns.set_palette('deep')\n",
    "DATA_PATH = Path(\"../../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "\n",
    "Load data for ARIMAX model\n",
    "1. A target variable (e.g., débit_insitu)\n",
    "2. Two exogenous variables (e.g., P_cumul_7j, débit_mgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\n",
    "    DATA_PATH/'data_cumul.csv', \n",
    "    sep=';', \n",
    "    usecols=['time', 'P_mean', 'P_cumul_7j', 'débit_insitu', 'débit_mgb'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )\n",
    "data = data['2012-01-01':]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMA\n",
    "\n",
    "First we can check for how long flow data is self correlated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = ['débit_insitu']\n",
    "data = data[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80-20 split)\n",
    "train_mask = data.index < '2019-01-01'\n",
    "train_data = data[train_mask]\n",
    "test_data = data[~train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove seassonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality_handler = SeasonalityHandler()\n",
    "seasonality_handler.compute_seasonal_pattern(train_data)\n",
    "\n",
    "deseasonalized_train_data = seasonality_handler.remove_seasonality(train_data)\n",
    "deseasonalized_test_data = seasonality_handler.remove_seasonality(test_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "arima_data = deseasonalized_train_data[col]\n",
    "arima_data = arima_data[:\"2018-12-31\"]\n",
    "arima_scaler = RobustScaler()\n",
    "scaled_arima_data = arima_scaler.fit_transform(arima_data)\n",
    "arima_data = pd.DataFrame(scaled_arima_data, index=arima_data.index, columns=[\"q_obs\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding optimal hyperparameters order of magnitude"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last found optimal parameters: p=9; d=0; q=2\n",
    "find_optimal = False\n",
    "if find_optimal:\n",
    "    import warnings\n",
    "    warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "    model = auto_arima(arima_data[\"q_obs\"], max_p=20, max_q=10, max_d=3, seasonal=False)\n",
    "    print(model.summary())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross validation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Module for hyperparameter tuning using cross validation.\"\"\"\n",
    "\n",
    "from typing import Tuple, List, Dict, Optional\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from itertools import product\n",
    "from tqdm import tqdm\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "\n",
    "\n",
    "\"\"\"Module for time series cross validation.\"\"\"\n",
    "\n",
    "from typing import Tuple, List, Optional, Union, Callable\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from tqdm import tqdm\n",
    "\n",
    "class TimeSeriesCrossValidator:\n",
    "    \"\"\"Class to handle time series cross validation.\n",
    "    \n",
    "    This class implements time series specific cross validation approaches:\n",
    "    - Rolling window validation\n",
    "    - Expanding window validation\n",
    "    - Multiple horizon forecasting\n",
    "    \n",
    "    Attributes:\n",
    "        n_splits: int\n",
    "            Number of splits for cross validation\n",
    "        horizon: int\n",
    "            Forecast horizon (how many steps ahead to predict)\n",
    "        min_train_size: int\n",
    "            Minimum size of the training set\n",
    "        step: int\n",
    "            Step size between training sets\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        n_splits: int = 5,\n",
    "        horizon: int = 10,\n",
    "        min_train_size: Optional[int] = None,\n",
    "        step: int = 1\n",
    "    ):\n",
    "        \"\"\"Initialize TimeSeriesCrossValidator.\n",
    "        \n",
    "        Args:\n",
    "            n_splits: Number of splits for cross validation\n",
    "            horizon: Number of steps to forecast\n",
    "            min_train_size: Minimum size of training set. If None, will be set based on data\n",
    "            step: Number of steps between training sets\n",
    "        \"\"\"\n",
    "        self.n_splits = n_splits\n",
    "        self.horizon = horizon\n",
    "        self.min_train_size = min_train_size\n",
    "        self.step = step\n",
    "        \n",
    "    def _get_time_series_split(self, data: pd.DataFrame) -> TimeSeriesSplit:\n",
    "        \"\"\"Create TimeSeriesSplit object with appropriate parameters.\"\"\"\n",
    "        if self.min_train_size is None:\n",
    "            self.min_train_size = len(data) // (self.n_splits + 1)\n",
    "            \n",
    "        return TimeSeriesSplit(\n",
    "            n_splits=self.n_splits,\n",
    "            test_size=self.horizon,\n",
    "            gap=0,\n",
    "            max_train_size=None\n",
    "        )\n",
    "    \n",
    "    def rolling_window_split(\n",
    "        self, \n",
    "        data: pd.DataFrame,\n",
    "        fixed_window: bool = True\n",
    "    ) -> List[Tuple[np.ndarray, np.ndarray]]:\n",
    "        \"\"\"Generate rolling window splits of the data.\n",
    "        \n",
    "        Args:\n",
    "            data: Time series data\n",
    "            fixed_window: If True, use fixed size windows. If False, use expanding windows\n",
    "            \n",
    "        Returns:\n",
    "            List of (train_idx, test_idx) tuples\n",
    "        \"\"\"\n",
    "        tss = self._get_time_series_split(data)\n",
    "        splits = []\n",
    "        \n",
    "        for train_idx, test_idx in tss.split(data):\n",
    "            if fixed_window:\n",
    "                # For fixed window, only take the last min_train_size points\n",
    "                if len(train_idx) > self.min_train_size:\n",
    "                    train_idx = train_idx[-self.min_train_size:]\n",
    "            splits.append((train_idx, test_idx))\n",
    "            \n",
    "        return splits\n",
    "    \n",
    "    def cross_validate_model(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        model_func: Callable,\n",
    "        fixed_window: bool = True,\n",
    "        **model_params\n",
    "    ) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "        \"\"\"Perform cross validation using the specified model.\n",
    "        \n",
    "        Args:\n",
    "            data: Time series data\n",
    "            model_func: Function that creates and fits the model\n",
    "            fixed_window: Whether to use fixed or expanding window\n",
    "            **model_params: Parameters to pass to the model function\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (predictions, actual values) for each split\n",
    "        \"\"\"\n",
    "        splits = self.rolling_window_split(data, fixed_window)\n",
    "        predictions = []\n",
    "        actuals = []\n",
    "        \n",
    "        for train_idx, test_idx in tqdm(splits, desc=\"Cross validation\"):\n",
    "            # Get train and test data\n",
    "            train_data = data.iloc[train_idx]\n",
    "            test_data = data.iloc[test_idx]\n",
    "            \n",
    "            # Fit model and make predictions\n",
    "            model = model_func(train_data, **model_params)\n",
    "            pred = model.forecast(steps=len(test_idx))\n",
    "            \n",
    "            predictions.append(pred)\n",
    "            actuals.append(test_data.values)\n",
    "            \n",
    "        return predictions, actuals\n",
    "    \n",
    "    def cross_validate_arima(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        order: Tuple[int, int, int],\n",
    "        fixed_window: bool = True\n",
    "    ) -> Tuple[List[np.ndarray], List[np.ndarray]]:\n",
    "        \"\"\"Convenience method for ARIMA cross validation.\n",
    "        \n",
    "        Args:\n",
    "            data: Time series data\n",
    "            order: ARIMA order (p,d,q)\n",
    "            fixed_window: Whether to use fixed or expanding window\n",
    "            \n",
    "        Returns:\n",
    "            Tuple of (predictions, actual values) for each split\n",
    "        \"\"\"\n",
    "        def arima_func(train_data, order):\n",
    "            model = ARIMA(train_data, order=order)\n",
    "            return model.fit()\n",
    "            \n",
    "        return self.cross_validate_model(\n",
    "            data=data,\n",
    "            model_func=arima_func,\n",
    "            fixed_window=fixed_window,\n",
    "            order=order\n",
    "        )\n",
    "    \n",
    "    def get_cv_scores(\n",
    "        self,\n",
    "        predictions: List[np.ndarray],\n",
    "        actuals: List[np.ndarray],\n",
    "        metric_funcs: dict\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Calculate cross validation scores.\n",
    "        \n",
    "        Args:\n",
    "            predictions: List of predictions for each split\n",
    "            actuals: List of actual values for each split\n",
    "            metric_funcs: Dictionary of metric names and functions\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with cross validation scores\n",
    "        \"\"\"\n",
    "        scores = []\n",
    "        for split_idx, (pred, actual) in enumerate(zip(predictions, actuals)):\n",
    "            split_scores = {'split': split_idx}\n",
    "            for name, func in metric_funcs.items():\n",
    "                split_scores[name] = func(actual, pred)\n",
    "            scores.append(split_scores)\n",
    "            \n",
    "        return pd.DataFrame(scores)\n",
    "\n",
    "class ARIMAHyperparameterTuner:\n",
    "    \"\"\"Class to handle hyperparameter tuning for ARIMA models using cross validation.\n",
    "    \n",
    "    This class implements a grid search over ARIMA parameters using time series\n",
    "    cross validation to find the best parameters based on prediction performance.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        cv_splits: int = 5,\n",
    "        horizon: int = 10,\n",
    "        min_train_size: Optional[int] = None,\n",
    "        metric: str = 'rmse'\n",
    "    ):\n",
    "        \"\"\"Initialize the tuner.\n",
    "        \n",
    "        Args:\n",
    "            cv_splits: Number of cross validation splits\n",
    "            horizon: Forecast horizon for each validation\n",
    "            min_train_size: Minimum size of training set\n",
    "            metric: Metric to optimize ('rmse', 'mae', or 'mse')\n",
    "        \"\"\"\n",
    "        self.cv = TimeSeriesCrossValidator(\n",
    "            n_splits=cv_splits,\n",
    "            horizon=horizon,\n",
    "            min_train_size=min_train_size\n",
    "        )\n",
    "        self.metric = metric\n",
    "        self.results_ = None\n",
    "        self.best_params_ = None\n",
    "        \n",
    "    def _calculate_metric(self, y_true: np.ndarray, y_pred: np.ndarray) -> float:\n",
    "        \"\"\"Calculate the specified metric.\"\"\"\n",
    "        if self.metric == 'rmse':\n",
    "            return np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "        elif self.metric == 'mae':\n",
    "            return mean_absolute_error(y_true, y_pred)\n",
    "        elif self.metric == 'mse':\n",
    "            return mean_squared_error(y_true, y_pred)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown metric: {self.metric}\")\n",
    "    \n",
    "    def grid_search(\n",
    "        self,\n",
    "        data: pd.DataFrame,\n",
    "        p_range: range,\n",
    "        d_range: range,\n",
    "        q_range: range,\n",
    "        fixed_window: bool = True\n",
    "    ) -> pd.DataFrame:\n",
    "        \"\"\"Perform grid search over ARIMA parameters.\n",
    "        \n",
    "        Args:\n",
    "            data: Time series data\n",
    "            p_range: Range of p values to try\n",
    "            d_range: Range of d values to try\n",
    "            q_range: Range of q values to try\n",
    "            fixed_window: Whether to use fixed size windows in CV\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with results for each parameter combination\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        param_combinations = list(product(p_range, d_range, q_range))\n",
    "        \n",
    "        for p, d, q in tqdm(param_combinations, desc=\"Parameter combinations\"):\n",
    "            try:\n",
    "                # Get predictions for all CV splits\n",
    "                predictions, actuals = self.cv.cross_validate_arima(\n",
    "                    data=data,\n",
    "                    order=(p, d, q),\n",
    "                    fixed_window=fixed_window\n",
    "                )\n",
    "                \n",
    "                # Calculate metrics for each split\n",
    "                split_scores = []\n",
    "                for pred, actual in zip(predictions, actuals):\n",
    "                    score = self._calculate_metric(actual, pred)\n",
    "                    split_scores.append(score)\n",
    "                \n",
    "                # Store results\n",
    "                results.append({\n",
    "                    'p': p,\n",
    "                    'd': d,\n",
    "                    'q': q,\n",
    "                    f'mean_{self.metric}': np.mean(split_scores),\n",
    "                    f'std_{self.metric}': np.std(split_scores),\n",
    "                    'n_splits': len(split_scores),\n",
    "                    'convergence': True\n",
    "                })\n",
    "            except Exception as e:\n",
    "                # Handle cases where model fails to converge\n",
    "                results.append({\n",
    "                    'p': p,\n",
    "                    'd': d,\n",
    "                    'q': q,\n",
    "                    f'mean_{self.metric}': np.inf,\n",
    "                    f'std_{self.metric}': np.inf,\n",
    "                    'n_splits': 0,\n",
    "                    'convergence': False,\n",
    "                    'error': str(e)\n",
    "                })\n",
    "        \n",
    "        # Convert results to DataFrame\n",
    "        self.results_ = pd.DataFrame(results)\n",
    "        \n",
    "        # Find best parameters\n",
    "        converged_results = self.results_[self.results_['convergence']]\n",
    "        if len(converged_results) > 0:\n",
    "            best_idx = converged_results[f'mean_{self.metric}'].idxmin()\n",
    "            self.best_params_ = tuple(\n",
    "                self.results_.loc[best_idx, ['p', 'd', 'q']].astype(int)\n",
    "            )\n",
    "        \n",
    "        return self.results_\n",
    "    \n",
    "    def plot_results(self, top_n: int = 10):\n",
    "        \"\"\"Plot the top N parameter combinations.\n",
    "        \n",
    "        Args:\n",
    "            top_n: Number of top results to plot\n",
    "        \"\"\"\n",
    "        import matplotlib.pyplot as plt\n",
    "        import seaborn as sns\n",
    "        \n",
    "        if self.results_ is None:\n",
    "            raise ValueError(\"No results available. Run grid_search first.\")\n",
    "            \n",
    "        # Get top N converged results\n",
    "        top_results = self.results_[self.results_['convergence']].nsmallest(\n",
    "            top_n, f'mean_{self.metric}'\n",
    "        )\n",
    "        \n",
    "        # Create plot\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        sns.barplot(\n",
    "            data=top_results,\n",
    "            y=top_results.apply(\n",
    "                lambda x: f\"({int(x['p'])},{int(x['d'])},{int(x['q'])})\", \n",
    "                axis=1\n",
    "            ),\n",
    "            x=f'mean_{self.metric}',\n",
    "            xerr=top_results[f'std_{self.metric}']\n",
    "        )\n",
    "        plt.title(f'Top {top_n} ARIMA Parameters')\n",
    "        plt.xlabel(f'Mean {self.metric.upper()}')\n",
    "        plt.ylabel('Parameters (p,d,q)')\n",
    "        plt.tight_layout()\n",
    "        \n",
    "        return plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the tuner\n",
    "tuner = ARIMAHyperparameterTuner(\n",
    "    cv_splits=10,          # number of CV splits\n",
    "    horizon=10,           # forecast horizon\n",
    "    min_train_size=90,   # minimum training size\n",
    "    metric='rmse'         # metric to optimize\n",
    ")\n",
    "\n",
    "# Define parameter ranges to search\n",
    "# Start with ranges around your auto_arima results\n",
    "p_range = range(8, 11)    # centered around p=9\n",
    "d_range = range(0, 2)     # including d=0 and d=1\n",
    "q_range = range(1, 4)     # centered around q=2\n",
    "\n",
    "# Run grid search\n",
    "results = tuner.grid_search(\n",
    "    data=train_data,      # use only training data\n",
    "    p_range=p_range,\n",
    "    d_range=d_range,\n",
    "    q_range=q_range,\n",
    "    fixed_window=False     # use fixed size windows\n",
    ")\n",
    "\n",
    "# Print best parameters\n",
    "print(f\"Best parameters: {tuner.best_params_}\")\n",
    "\n",
    "# Plot top results\n",
    "tuner.plot_results(top_n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_test_data = deseasonalized_test_data[col]\n",
    "scaled_arima_test_data = arima_scaler.transform(arima_test_data)\n",
    "arima_test_data = pd.DataFrame(scaled_arima_test_data, index=arima_test_data.index, columns=[\"q_obs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arima_test_data.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "from tqdm import tqdm\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "forecast_horizon = 10\n",
    "context_length = 120\n",
    "forecast = []\n",
    "p=9; d=0; q=2\n",
    "for i in tqdm(range(context_length, len(arima_test_data), 5)):\n",
    "    step_data=arima_test_data[i-context_length:i]\n",
    "    dry_season = (step_data.abs() <=0.5).all().values[0]\n",
    "    if not dry_season:\n",
    "        model = ARIMA(step_data[\"q_obs\"], order=(p, d, q))\n",
    "        model_fit = model.fit()\n",
    "        # print(model_fit.summary())\n",
    "        forecast.append(model_fit.forecast(steps=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_forecast = []\n",
    "for f in forecast:\n",
    "    formatted_forecast.append({\"time\":f.index[0], **{f\"t+{i+1}\":f[i] for i in range(f.index.size)}})\n",
    "_ = pd.DataFrame(formatted_forecast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_.set_index(\"time\", inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = pd.DataFrame(arima_scaler.inverse_transform(_), index=_.index, columns=_.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasonality_handler.add_seasonality(_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Predictions and Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make predictions\n",
    "predictions = model_fit.predict(start=len(train_data), end=len(data)-1,)\n",
    "rescaled_predictions = arima_scaler.inverse_transform(predictions.to_frame())\n",
    "predictions = pd.DataFrame(rescaled_predictions, index=predictions.index, columns=['débit_insitu'])\n",
    "predictions = seasonality_handler.add_seasonality(predictions)\n",
    "\n",
    "# Calculate error metrics\n",
    "mse = mean_squared_error(test_data['débit_insitu'], predictions)\n",
    "rmse = np.sqrt(mse)\n",
    "mae = mean_absolute_error(test_data['débit_insitu'], predictions)\n",
    "\n",
    "print(f'Mean Squared Error: {mse:.2f}')\n",
    "print(f'Root Mean Squared Error: {rmse:.2f}')\n",
    "print(f'Mean Absolute Error: {mae:.2f}')\n",
    "\n",
    "def smooth(data, window_size): return data.rolling(window=window_size).mean()\n",
    "# Plot actual vs predicted values\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.plot(test_data.index.get_level_values(\"time\"), test_data['débit_insitu'], label='Actual')\n",
    "plt.plot(test_data.index.get_level_values(\"time\"), predictions, label='Predicted')\n",
    "plt.title('ARIMAX: Actual vs Predicted Flow')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Flow')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Diagnostics\n",
    "\n",
    "Let's examine the model residuals to check if our model assumptions are met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get model residuals\n",
    "residuals = pd.DataFrame(model_fit.resid)\n",
    "\n",
    "# Plot residuals\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "fig.suptitle('Model Diagnostics')\n",
    "\n",
    "# Residuals over time\n",
    "residuals.plot(ax=axes[0,0], title='Residuals over Time')\n",
    "axes[0,0].set_xlabel('Date')\n",
    "axes[0,0].set_ylabel('Residual')\n",
    "\n",
    "# Residuals histogram\n",
    "residuals.hist(ax=axes[0,1], bins=30)\n",
    "axes[0,1].set_title('Residuals Distribution')\n",
    "\n",
    "# Q-Q plot\n",
    "from scipy import stats\n",
    "stats.probplot(residuals.iloc[:,0], dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot')\n",
    "\n",
    "# Autocorrelation plot\n",
    "pd.plotting.autocorrelation_plot(residuals.iloc[:,0], ax=axes[1,1])\n",
    "axes[1,1].set_title('Residuals Autocorrelation')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "def grid_search_arima(data, p_range, d_range, q_range):\n",
    "    best_scores = []\n",
    "    \n",
    "    for p, d, q in product(p_range, d_range, q_range):\n",
    "        try:\n",
    "            model = ARIMA(data, order=(p, d, q))\n",
    "            results = model.fit()\n",
    "            best_scores.append({\n",
    "                'p': p,\n",
    "                'd': d,\n",
    "                'q': q,\n",
    "                'aic': results.aic,\n",
    "                'bic': results.bic,\n",
    "                'hqic': results.hqic,\n",
    "                'loglikelihood': results.llf,\n",
    "            })\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return pd.DataFrame(best_scores).set_index([\"p\", \"d\", \"q\"]).sort_values('aic')  # Sort by AIC\n",
    "\n",
    "# Example usage\n",
    "p_range = range(5, 7+1)\n",
    "d_range = range(1, 1+1)\n",
    "q_range = range(5, 7+1)\n",
    "\n",
    "results = grid_search_arima(arima_data[\"q_obs\"], p_range, d_range, q_range)\n",
    "best_params = results.iloc[0]['order']  # Get parameters with lowest AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(scores).set_index([\"p\", \"d\", \"q\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusions\n",
    "\n",
    "The ARIMAX model we built demonstrates how to:\n",
    "1. Incorporate exogenous variables (temperature and marketing spend) into time series forecasting\n",
    "2. Make predictions on test data\n",
    "3. Evaluate model performance using various metrics\n",
    "4. Perform model diagnostics\n",
    "\n",
    "To improve the model, you could:\n",
    "1. Tune the ARIMAX parameters (p,d,q) using grid search or AIC/BIC criteria\n",
    "2. Add seasonal components (SARIMAX)\n",
    "3. Include more relevant exogenous variables\n",
    "4. Handle any seasonality or trends in the data preprocessing step"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ARIMAX\n",
    "\n",
    "We'll split our data into training and testing sets, and prepare the exogenous variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Visualization\n",
    "\n",
    "Let's visualize our time series data to understand the patterns and relationships."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot time series\n",
    "fig, axes = plt.subplots(3, 1, figsize=(15, 12))\n",
    "fig.suptitle('Time Series Components')\n",
    "\n",
    "# Sales\n",
    "data['débit_insitu'].plot(ax=axes[0], title='Water flow over Time')\n",
    "axes[0].set_xlabel('')\n",
    "axes[0].set_ylabel('débit_insitu')\n",
    "\n",
    "# Temperature\n",
    "data['P_cumul_7j'].plot(ax=axes[1], title='Rain cumul over Time')\n",
    "axes[1].set_xlabel('')\n",
    "axes[1].set_ylabel('P_cumul_7j')\n",
    "\n",
    "# Marketing Spend\n",
    "data['débit_mgb'].plot(ax=axes[2], title='MGB model prediction over Time')\n",
    "axes[2].set_xlabel('Date')\n",
    "axes[2].set_ylabel('débit_mgb')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set feature (exogeneous) and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col, y_col = ['P_cumul_7j', 'débit_mgb'], ['débit_insitu']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test sets (80-20 split)\n",
    "train_mask = data.index < '2019-01-01'\n",
    "train_data = data[train_mask]\n",
    "test_data = data[~train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Remove seassonality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seasson = train_data.groupby(train_data.index.isocalendar().week).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deseasonalize_weekofyear(data, seasson):\n",
    "    data['week'] = data.index.isocalendar().week\n",
    "    data.set_index('week', inplace=True, append=True)\n",
    "    deseasonalized = data - seasson\n",
    "    deseasonalized.reset_index(level='week', drop=True, inplace=True)\n",
    "    return deseasonalized\n",
    "\n",
    "deseasonalized_train_data = deseasonalize_weekofyear(train_data, seasson)\n",
    "deseasonalized_test_data = deseasonalize_weekofyear(test_data, seasson)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create features with context and target with horizon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ombs_senegal.benchmark_model import FeatureGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_generator = FeatureGenerator()\n",
    "x_train_with_context, y_train_with_horizon = feature_generator.generate(deseasonalized_train_data, x_col, y_col)\n",
    "x_test_with_context, y_test_with_context = feature_generator.generate(deseasonalized_test_data, x_col, y_col)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Training set size: {len(x_train_with_context)}\")\n",
    "print(f\"Test set size: {len(x_test_with_context)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "features_scaler = RobustScaler()\n",
    "exog_train = features_scaler.fit_transform(x_train_with_context)\n",
    "exog_test = features_scaler.transform(x_test_with_context)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build and Train ARIMAX Model\n",
    "\n",
    "We'll use the SARIMAX class from statsmodels to implement our ARIMAX model. The order parameters (p,d,q) will be set to (1,1,1) for this example, but in practice, you should use techniques like AIC/BIC or grid search to find optimal parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and train ARIMAX model\n",
    "model = SARIMAX(y_train_with_horizon,\n",
    "                exog=exog_train,\n",
    "                order=(1, 1, 1),\n",
    "                enforce_stationarity=False,\n",
    "                enforce_invertibility=False)\n",
    "\n",
    "model_fit = model.fit(disp=False)\n",
    "print(model_fit.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
