{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmark Models\n",
    "\n",
    "This notebook implements benchmark for IMERG rain data as predictor for the water discharge for the Senegal river"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "from ombs_senegal.benchmark_model import FeatureGenerator, SimpleRegressionModel, BenchmarkScores\n",
    "from ombs_senegal.benchmark_model import plot_interactive_benchmark_scores, plot_prediction_comparison"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DATA_PATH = Path(\"../../data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(DATA_PATH/\"data_cumul.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    DATA_PATH/'data_cumul.csv', \n",
    "    sep=';', \n",
    "    usecols=['time', 'P_mean', 'P_cumul_7j', 'débit_insitu', 'débit_mgb'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(df):\n",
    "    return (df - df.min()) / (df.max() - df.min())\n",
    "\n",
    "normalize(df).plot()#.hvplot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col, y_col = ['P_cumul_7j','débit_mgb'], ['débit_insitu']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mask = df.index < '2019-01-01'\n",
    "train = df[train_mask]\n",
    "valid = df[~train_mask]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaler = RobustScaler()\n",
    "train[x_col] = features_scaler.fit_transform(train[x_col])\n",
    "valid[x_col] = features_scaler.transform(valid[x_col])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = []\n",
    "scores = []\n",
    "for degree in range(1, 4):\n",
    "    for window in range(10, 51, 10):\n",
    "        feature_generator = FeatureGenerator(context_window=window, target_window=10, degree=degree)        \n",
    "        train_x, train_y = feature_generator.generate(train, x_col, y_col)\n",
    "        valid_x, valid_y = feature_generator.generate(valid, x_col, y_col)\n",
    "\n",
    "        model = SimpleRegressionModel()\n",
    "        model.fit(train_x, train_y)\n",
    "        predictions.append(model.predict_as_dataframe(valid_x, degree=degree, ctx_window=window))\n",
    "\n",
    "predictions = pd.concat(predictions).reorder_levels(['degree', 'ctx_window', 'time']).to_xarray()\n",
    "observations = valid[y_col].to_xarray().sel(time=slice(predictions.time.min(), predictions.time.max()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scoring\n",
    "\n",
    "Since we have generated multiple predictions with different parameters, we will select only the best performing models according to each metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "benchmark_scores = BenchmarkScores()\n",
    "scores_ds = benchmark_scores.compute_scores(\n",
    "    predictions.to_array(),\n",
    "    observations[\"débit_insitu\"],\n",
    "    [\"mae\", \"rmse\", \"nse\", \"kge\"])\n",
    "best_scores = benchmark_scores.find_nbest_scores(\n",
    "    scores_ds,\n",
    "    how={\"mae\": \"min\", \"rmse\": \"min\", \"nse\": \"max\", \"kge\": \"max\"},\n",
    "    n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_benchmark_scores(best_scores,)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the scatter plot comparing MAE vs MSE metrics, we can conclude that polynomial regression with degree 2 and window sizes between 30-50 days provides the optimal predictions. This is evident from the cluster of points in the lower left corner of the plot, which indicates lower error rates for both metrics. Specifically, the combinations of degree=2 with windows around 40 days achieve the best balance between Mean Absolute Error and Mean Squared Error, suggesting these parameters offer the most accurate and stable predictions without overfitting the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Time series verification\n",
    "\n",
    "Now that we have identified the optimal model parameters, let's verify its performance by comparing the predicted discharge values with both observed values and MGB model predictions. This comparison will be done across the full 10-day prediction horizon to assess how well our model maintains its predictive power over time. We'll visualize these comparisons using time series plots that show the observed discharge, our model's predictions, and the MGB model predictions side by side.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first define the optimal models as follors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models={\n",
    "    \"t+1\": {\"degree\": 2, \"ctx_window\": 40}, \n",
    "    **{f\"t+{i}\": {\"degree\": 2, \"ctx_window\": 50} for i in range(2, 11)}\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_prediction_comparison(\n",
    "    observed=observations[\"débit_insitu\"], \n",
    "    predicted=predictions, \n",
    "    best_model=best_models, \n",
    "    mgb=df[~train_mask][\"débit_mgb\"].to_xarray(),\n",
    "    scores=scores_ds\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save prediction data\n",
    "\n",
    "We save the best model for later use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# benchmark_ds = results_ds.sel(degree=2, window=slice(30,50))\n",
    "# benchmark_ds.to_netcdf(DATA_PATH/'regression_benchmark.nc')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
