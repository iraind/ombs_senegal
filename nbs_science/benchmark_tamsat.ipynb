{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAMSAT Pertinence Analysis\n",
    "\n",
    "This notebook analyzes the relevance of TAMSAT (Tropical Applications of Meteorology using SATellite data) rainfall data for hydrological modeling in Senegal. It explores the relationship between TAMSAT precipitation estimates and river discharge measurements to assess the dataset's utility for flood forecasting and water resource management in the region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ombs_senegal.region import get_region_mask\n",
    "\n",
    "\n",
    "DATA_PATH = Path(\"../../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAMSAT Data preprocessing\n",
    "\n",
    "This section preprocesses TAMSAT rainfall data. First we will load and mask TAMSAT data over the region of interest\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_gdf = gpd.read_file(DATA_PATH/\"point_ajustement/sub4/sub4_senegal.shp\")\n",
    "bounds = roi_gdf.geometry.bounds\n",
    "min_lat, max_lat = bounds[\"miny\"].values, bounds[\"maxy\"].values\n",
    "min_lon, max_lon = bounds[\"minx\"].values, bounds[\"maxx\"].values\n",
    "\n",
    "tamsat = xr.open_dataset(DATA_PATH/\"01-tamsatDaily.v3.1-20100101-20250531-20250603_-16.85_-6.05_10.15_18.95.nc\")\n",
    "tamsat = tamsat.sel(lat=slice(floor(min_lat), ceil(max_lat), -1), lon=slice(floor(min_lon), ceil(max_lon)))\n",
    "mask = get_region_mask(tamsat, roi_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "roi_tamsat = tamsat.where(mask)\n",
    "roi_tamsat = roi_tamsat.sel(time=slice(None, \"2024-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're interested in the total rainfall across the basin rather than its spatial distribution, we'll sum up all rainfall values within the basin area. We'll save this aggregated data to avoid repeating the preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "daily_total = roi_tamsat.sum([\"lat\", \"lon\"])\n",
    "daily_total.to_netcdf(DATA_PATH/\"tamsat_sub4_senegal_daily_total.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAMSAT estimate to in situ correlation\n",
    "\n",
    "We will analyze the correlation between TAMSAT rainfall estimates and observed river discharge (débit).\n",
    "To reduce noise and identify long-term patterns, we'll aggregate the data annually. This will help us:\n",
    "1. Evaluate how well TAMSAT rainfall estimates correspond to actual river flow\n",
    "2. Assess the potential effectiveness of using TAMSAT data in our benchmark model\n",
    "3. Account for seasonal patterns and lag effects between rainfall and discharge\n",
    "\n",
    "The correlation analysis will provide insights into whether TAMSAT data can be a reliable predictor for river discharge in our study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insitu_df = pd.read_csv(\n",
    "    DATA_PATH/'data_cumul.csv', \n",
    "    sep=';', \n",
    "    usecols=['time', 'débit_insitu', 'P_mean'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )\n",
    "\n",
    "tamsat_daily_total = xr.load_dataset(DATA_PATH/\"tamsat_sub4_senegal_daily_total.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(insitu_df, tamsat_daily_total[\"rfe\"].to_dataframe(), left_index=True, right_index=True)\n",
    "yearly_df = combined_df.resample(\"YS\").sum()\n",
    "yearly_df = (yearly_df - yearly_df.min())/(yearly_df.max() - yearly_df.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(x, y):\n",
    "    res = x.sub(y).pow(2).sum()\n",
    "    tot = x.sub(x.mean()).pow(2).sum()\n",
    "    return 1 - res/tot\n",
    "\n",
    "r2(yearly_df[\"débit_insitu\"], yearly_df[\"rfe\"]), r2(yearly_df[\"débit_insitu\"], yearly_df[\"P_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(yearly_df['débit_insitu'], yearly_df['rfe'], label='TAMSAT')\n",
    "plt.scatter(yearly_df['débit_insitu'], yearly_df['P_mean'], label='IMERG')\n",
    "\n",
    "# Add year labels to each point\n",
    "for idx, row in yearly_df.iterrows():\n",
    "    plt.annotate(idx.year, (row['débit_insitu'], row['rfe']), xytext=(5,5), textcoords='offset points')\n",
    "    plt.annotate(idx.year, (row['débit_insitu'], row['P_mean']), xytext=(5,5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Débit in-situ')\n",
    "plt.ylabel('Rainfall Estimate (mm)')\n",
    "plt.title('Débit vs Rainfall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph, in addition to the r2 scores, shows that the correlation between TAMSAT and the river flow is smaller and expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross correlation\n",
    "\n",
    "In order to determine the optimal smoothing window size, we will calculate the cross correlation between the rainfall and the river flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "import pandas as pd\n",
    "\n",
    "def find_optimal_window(\n",
    "        rainfall: pd.Series,\n",
    "        discharge: pd.Series,\n",
    "        max_window: int = 100, \n",
    "        min_lag: int = 0, \n",
    "        max_lag: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"Find optimal smoothing window with constrained lag range between rainfall and discharge time series.\"\"\"\n",
    "    def smooth(df, window, missing_val=0): return df.rolling(window=window).sum().fillna(missing_val)\n",
    "\n",
    "    results = []    \n",
    "    for window in range(1, max_window + 1):\n",
    "\n",
    "        smoothed_rain = smooth(rainfall, window=window)\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_mask = ~np.isnan(smoothed_rain)\n",
    "        smooth_rain_clean = smoothed_rain[valid_mask]\n",
    "        discharge_clean = discharge[valid_mask]\n",
    "        \n",
    "        cross_corr = ccf(smooth_rain_clean, discharge_clean)\n",
    "        \n",
    "        # Only consider the specified lag range\n",
    "        lag_range = slice(min_lag, max_lag + 1)\n",
    "        restricted_ccf = cross_corr[lag_range]\n",
    "        \n",
    "        max_corr = np.max(np.abs(restricted_ccf))\n",
    "        lag = np.argmax(np.abs(restricted_ccf)) + min_lag\n",
    "        \n",
    "        results.append({\n",
    "            'window': window,\n",
    "            'correlation': max_corr,\n",
    "            'lag': lag\n",
    "        })\n",
    "            \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_correlations = find_optimal_window(combined_df['rfe'], combined_df['débit_insitu'])\n",
    "best_correlations.hvplot.line(x='window', y='correlation', hover_cols=['lag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best correlation is around 60 days of window size. We will now take a closer look by plotting the smoothed and normalized daily data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(df, window=7, missing_val=0): return df.rolling(window=window).sum().fillna(missing_val)\n",
    "\n",
    "def normalize(df): return (df - df.min())/(df.max() - df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 60\n",
    "processed_df = combined_df.copy()\n",
    "processed_df[f\"rfe_w={window}\"] = smooth(combined_df[\"rfe\"], window=window)\n",
    "normalized_df = normalize(processed_df)\n",
    "\n",
    "normalized_df[[f\"rfe_w={window}\", \"débit_insitu\"]].hvplot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a window size of 60 days yields the highest correlation, this longer aggregation period may smooth out important short-term variations in the rainfall-discharge relationship. A shorter window size might better capture these finer temporal dynamics, albeit with potentially lower overall correlation. Based on the previous optimal correlation windows, we will choose:\n",
    "- 3 days, as it captures the immediate rainfall-discharge response while still showing linear improvement in correlation\n",
    "- 7 days, as this is where the correlation curve begins to stabilize, suggesting it captures the main rainfall-discharge dynamics\n",
    "- 15 days, as it provides a good compromise between short-term responsiveness and longer-term accumulation effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = combined_df.copy()\n",
    "w_vars = []\n",
    "for window in [3, 7, 15, 60]:\n",
    "    processed_df[f\"rfe_w={window}\"] = smooth(combined_df[\"rfe\"], window=window)\n",
    "    w_vars += [f\"rfe_w={window}\"]\n",
    "\n",
    "normalize(processed_df)[[*w_vars, \"débit_insitu\"]].hvplot.line(width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Benchmark with TAMSAT \n",
    "\n",
    "Based on the strong correlation observed between TAMSAT rainfall estimates and river flow, we will now evaluate the benchmark model using TAMSAT data. We will conduct two analyses:\n",
    "1. Using only TAMSAT rainfall estimates and MGB water flow predictions as input features\n",
    "2. Using all available parameters (TAMSAT rainfall, MGB flow, and other variables) as input features\n",
    "\n",
    "Similar to our previous analysis with IMERG data, we will:\n",
    "- Test different time window sizes to capture temporal patterns\n",
    "- Evaluate multiple polynomial degrees to model non-linear relationships\n",
    "- Compare model performance using standard metrics (MSE, MAE) and visual analysis\n",
    "\n",
    "This will allow us to:\n",
    "- Assess TAMSAT's effectiveness as a predictor\n",
    "- Compare results with the IMERG-based models\n",
    "- Determine optimal model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from ombs_senegal.benchmark_model import FeatureGenerator, SimpleRegressionModel, BenchmarkScores\n",
    "from ombs_senegal.benchmark_model import plot_interactive_benchmark_scores, plot_prediction_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "df = pd.read_csv(\n",
    "    DATA_PATH/'data_cumul.csv', \n",
    "    sep=';', \n",
    "    usecols=['time', 'P_cumul_7j', 'débit_insitu', 'débit_mgb'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )\n",
    "\n",
    "tamsat_daily_total = xr.load_dataset(DATA_PATH/\"tamsat_sub_poly_daily_total.nc\")\n",
    "\n",
    "data = pd.merge(df, tamsat_daily_total[\"rfe\"].to_dataframe(), left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col, y_col = [\"débit_mgb\", \"rfe\"], ['débit_insitu']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smooth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rfe\"] = smooth(data[\"rfe\"], window=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaler = RobustScaler()\n",
    "\n",
    "features = data[x_col]\n",
    "data[x_col] = features_scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "train_mask = df.index < '2019-01-01'\n",
    "\n",
    "train = data[train_mask]\n",
    "valid = data[~train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = []\n",
    "for degree in range(1, 4):\n",
    "    for window in range(10, 51, 10):\n",
    "        feature_generator = FeatureGenerator(context_window=window, target_window=10, degree=degree)        \n",
    "        train_x, train_y = feature_generator.generate(train, x_col, y_col)\n",
    "        valid_x, valid_y = feature_generator.generate(valid, x_col, y_col)\n",
    "\n",
    "        model = SimpleRegressionModel()\n",
    "        model.fit(train_x, train_y)\n",
    "        predictions.append(model.predict_as_dataframe(valid_x, degree=degree, ctx_window=window))\n",
    "\n",
    "\n",
    "predictions = pd.concat(predictions).reorder_levels(['degree', 'ctx_window', 'time']).to_xarray()\n",
    "observations = valid[y_col[0]].to_xarray().sel(time=slice(predictions.time.min(), predictions.time.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_scores = BenchmarkScores()\n",
    "scores_ds = benchmark_scores.compute_scores(\n",
    "    predictions,\n",
    "    observations,\n",
    "    [\"mae\", \"rmse\", \"nse\", \"kge\"])\n",
    "best_scores = benchmark_scores.find_nbest_scores(\n",
    "    scores_ds,\n",
    "    how={\"mae\": \"min\", \"rmse\": \"min\", \"nse\": \"max\", \"kge\": \"max\"},\n",
    "    n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_benchmark_scores(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the benchmark results shows the expected pattern of decreasing forecast accuracy as prediction horizons increase. \n",
    "\n",
    "Using a 15-day smoothing window for rainfall data, the model achieves optimal performance with polynomial features of degree 2 and context windows ranging from 30 to 50 timesteps. This configuration provides the best balance between capturing relevant temporal patterns while avoiding overfitting. In order to have a single global score, we will normalize the RMSE and the MAE and will make the mean of all the scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_metrics(ds):\n",
    "    dims = [\"degree\", \"ctx_window\"]\n",
    "    return 1 - (ds - ds.min(dim=dims))/(ds.max(dim=dims) - ds.min(dim=dims))\n",
    "\n",
    "\n",
    "normalized_scores = normalize_metrics(scores_ds)\n",
    "normalized_scores = normalized_scores.to_array().mean(dim=\"variable\")\n",
    "single_metric_best_scores = benchmark_scores.find_nbest_scores(normalized_scores.to_dataset(name=\"score\"), how={\"score\": \"max\"}, n=1)\n",
    "single_metric_best_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = {}\n",
    "for idx, row in single_metric_best_scores.reset_index().iterrows():\n",
    "    best_models[row[\"forecast_horizon\"]] = {\"degree\": row[\"degree\"], \"ctx_window\": row[\"ctx_window\"]}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_prediction_comparison(\n",
    "    observed=observations, \n",
    "    predicted=predictions, \n",
    "    best_model=best_models, \n",
    "    mgb=df[~train_mask][\"débit_mgb\"].to_xarray(),\n",
    "    scores=scores_ds\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "benchmark_ds = results_ds.sel(degree=2, window=slice(30,50))\n",
    "benchmark_ds.to_netcdf(DATA_PATH/'tamsat_regression_benchmark.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "\n",
    "# Calculate cross-correlation between rainfall and flow\n",
    "ccf_rfe = ccf(smooth(combined_df[\"rfe\"], window=30), combined_df['débit_insitu'], adjusted=False)\n",
    "#ccf_mgb = ccf(normalized_df['débit_mgb'], normalized_df['débit_insitu'], adjusted=False)\n",
    "\n",
    "# Plot cross-correlations\n",
    "plt.figure(figsize=(10,6))\n",
    "lags = range(len(ccf_rfe))\n",
    "plt.plot(lags, ccf_rfe, label='TAMSAT RFE vs In-situ Flow')\n",
    "#plt.plot(lags, ccf_mgb, label='MGB Flow vs In-situ Flow')\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.xlabel('Lag (days)')\n",
    "plt.ylabel('Cross-correlation')\n",
    "plt.title('Cross-correlation Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
