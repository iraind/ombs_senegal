{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAMSAT Pertinence Analysis\n",
    "\n",
    "This notebook analyzes the relevance of TAMSAT (Tropical Applications of Meteorology using SATellite data) rainfall data for hydrological modeling in Senegal. It explores the relationship between TAMSAT precipitation estimates and river discharge measurements to assess the dataset's utility for flood forecasting and water resource management in the region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ombs_senegal.region import get_region_mask\n",
    "\n",
    "\n",
    "DATA_PATH = Path(\"../../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAMSAT Data preprocessing\n",
    "\n",
    "This section preprocesses TAMSAT rainfall data. First we will load and mask TAMSAT data over the region of interest\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_gdf = gpd.read_file(DATA_PATH/\"point_ajustement/sub4/sub4_senegal.shp\")\n",
    "bounds = roi_gdf.geometry.bounds\n",
    "min_lat, max_lat = bounds[\"miny\"].values, bounds[\"maxy\"].values\n",
    "min_lon, max_lon = bounds[\"minx\"].values, bounds[\"maxx\"].values\n",
    "\n",
    "tamsat = xr.open_dataset(DATA_PATH/\"01-tamsatDaily.v3.1-20100101-20250531-20250603_-16.85_-6.05_10.15_18.95.nc\")\n",
    "tamsat = tamsat.sel(lat=slice(floor(min_lat), ceil(max_lat), -1), lon=slice(floor(min_lon), ceil(max_lon)))\n",
    "mask = get_region_mask(tamsat, roi_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "roi_tamsat = tamsat.where(mask)\n",
    "roi_tamsat = roi_tamsat.sel(time=slice(None, \"2024-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're interested in the total rainfall across the basin rather than its spatial distribution, we'll sum up all rainfall values within the basin area. We'll save this aggregated data to avoid repeating the preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "daily_total = roi_tamsat.sum([\"lat\", \"lon\"])\n",
    "daily_total.to_netcdf(DATA_PATH/\"tamsat_sub4_senegal_daily_total.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAMSAT estimate to in situ correlation\n",
    "\n",
    "We will analyze the correlation between TAMSAT rainfall estimates and observed river discharge (débit).\n",
    "To reduce noise and identify long-term patterns, we'll aggregate the data annually. This will help us:\n",
    "1. Evaluate how well TAMSAT rainfall estimates correspond to actual river flow\n",
    "2. Assess the potential effectiveness of using TAMSAT data in our benchmark model\n",
    "3. Account for seasonal patterns and lag effects between rainfall and discharge\n",
    "\n",
    "The correlation analysis will provide insights into whether TAMSAT data can be a reliable predictor for river discharge in our study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "insitu_df = pd.read_csv(\n",
    "    DATA_PATH/'data_cumul.csv', \n",
    "    sep=';', \n",
    "    usecols=['time', 'débit_insitu', 'P_mean'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )\n",
    "\n",
    "tamsat_daily_total = xr.load_dataset(DATA_PATH/\"tamsat_sub4_senegal_daily_total.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = pd.merge(insitu_df, tamsat_daily_total[\"rfe\"].to_dataframe(), left_index=True, right_index=True)\n",
    "yearly_df = combined_df.resample(\"YS\").sum()\n",
    "yearly_df = (yearly_df - yearly_df.min())/(yearly_df.max() - yearly_df.min())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Yearly correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(x, y):\n",
    "    res = x.sub(y).pow(2).sum()\n",
    "    tot = x.sub(x.mean()).pow(2).sum()\n",
    "    return 1 - res/tot\n",
    "\n",
    "r2(yearly_df[\"débit_insitu\"], yearly_df[\"rfe\"]), r2(yearly_df[\"débit_insitu\"], yearly_df[\"P_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(yearly_df['débit_insitu'], yearly_df['rfe'], label='TAMSAT')\n",
    "plt.scatter(yearly_df['débit_insitu'], yearly_df['P_mean'], label='IMERG')\n",
    "\n",
    "# Add year labels to each point\n",
    "for idx, row in yearly_df.iterrows():\n",
    "    plt.annotate(idx.year, (row['débit_insitu'], row['rfe']), xytext=(5,5), textcoords='offset points')\n",
    "    plt.annotate(idx.year, (row['débit_insitu'], row['P_mean']), xytext=(5,5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Débit in-situ')\n",
    "plt.ylabel('Rainfall Estimate (mm)')\n",
    "plt.title('Débit vs Rainfall')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above graph, in addition to the r2 scores, shows that the correlation between TAMSAT and the river flow is smaller and expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cross correlation\n",
    "\n",
    "In order to determine the optimal smoothing window size, we will calculate the cross correlation between the rainfall and the river flow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "import pandas as pd\n",
    "\n",
    "def find_optimal_window(\n",
    "        rainfall: pd.Series,\n",
    "        discharge: pd.Series,\n",
    "        max_window: int = 100, \n",
    "        min_lag: int = 0, \n",
    "        max_lag: int = 30) -> pd.DataFrame:\n",
    "    \"\"\"Find optimal smoothing window with constrained lag range between rainfall and discharge time series.\"\"\"\n",
    "    def smooth(df, window, missing_val=0): return df.rolling(window=window).sum().fillna(missing_val)\n",
    "\n",
    "    results = []    \n",
    "    for window in range(1, max_window + 1):\n",
    "\n",
    "        smoothed_rain = smooth(rainfall, window=window)\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_mask = ~np.isnan(smoothed_rain)\n",
    "        smooth_rain_clean = smoothed_rain[valid_mask]\n",
    "        discharge_clean = discharge[valid_mask]\n",
    "        \n",
    "        cross_corr = ccf(smooth_rain_clean, discharge_clean)\n",
    "        \n",
    "        # Only consider the specified lag range\n",
    "        lag_range = slice(min_lag, max_lag + 1)\n",
    "        restricted_ccf = cross_corr[lag_range]\n",
    "        \n",
    "        max_corr = np.max(np.abs(restricted_ccf))\n",
    "        lag = np.argmax(np.abs(restricted_ccf)) + min_lag\n",
    "        \n",
    "        results.append({\n",
    "            'window': window,\n",
    "            'correlation': max_corr,\n",
    "            'lag': lag\n",
    "        })\n",
    "            \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_correlations = find_optimal_window(combined_df['rfe'], combined_df['débit_insitu'])\n",
    "best_correlations.hvplot.line(x='window', y='correlation', hover_cols=['lag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the best correlation is around 60 days of window size. We will now take a closer look by plotting the smoothed and normalized daily data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def smooth(df, window=7, missing_val=0): return df.rolling(window=window).sum().fillna(missing_val)\n",
    "\n",
    "def normalize(df): return (df - df.min())/(df.max() - df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = 60\n",
    "processed_df = combined_df.copy()\n",
    "processed_df[f\"rfe_w={window}\"] = smooth(combined_df[\"rfe\"], window=window)\n",
    "normalized_df = normalize(processed_df)\n",
    "\n",
    "normalized_df[[f\"rfe_w={window}\", \"débit_insitu\"]].hvplot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While a window size of 60 days yields the highest correlation, this longer aggregation period may smooth out important short-term variations in the rainfall-discharge relationship. A shorter window size might better capture these finer temporal dynamics, albeit with potentially lower overall correlation. Based on the previous optimal correlation windows, we will choose:\n",
    "- 3 days, as it captures the immediate rainfall-discharge response while still showing linear improvement in correlation\n",
    "- 7 days, as this is where the correlation curve begins to stabilize, suggesting it captures the main rainfall-discharge dynamics\n",
    "- 15 days, as it provides a good compromise between short-term responsiveness and longer-term accumulation effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_df = combined_df.copy()\n",
    "w_vars = []\n",
    "for window in [3, 7, 15, 60]:\n",
    "    processed_df[f\"rfe_w={window}\"] = smooth(combined_df[\"rfe\"], window=window)\n",
    "    w_vars += [f\"rfe_w={window}\"]\n",
    "\n",
    "normalize(processed_df)[[*w_vars, \"débit_insitu\"]].hvplot.line(width=1000, height=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Benchmark with TAMSAT \n",
    "\n",
    "Based on the strong correlation observed between TAMSAT rainfall estimates and river flow, we will now evaluate the benchmark model using TAMSAT data. We will conduct two analyses:\n",
    "1. Using only TAMSAT rainfall estimates and MGB water flow predictions as input features\n",
    "2. Using all available parameters (TAMSAT rainfall, MGB flow, and other variables) as input features\n",
    "\n",
    "Similar to our previous analysis with IMERG data, we will:\n",
    "- Test different time window sizes to capture temporal patterns\n",
    "- Evaluate multiple polynomial degrees to model non-linear relationships\n",
    "- Compare model performance using standard metrics (MSE, MAE) and visual analysis\n",
    "\n",
    "This will allow us to:\n",
    "- Assess TAMSAT's effectiveness as a predictor\n",
    "- Compare results with the IMERG-based models\n",
    "- Determine optimal model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from ombs_senegal.benchmark_model import FeatureGenerator, SimpleRegressionModel, BenchmarkScores\n",
    "from ombs_senegal.benchmark_model import plot_interactive_benchmark_scores, plot_prediction_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\n",
    "    DATA_PATH/'data_cumul.csv', \n",
    "    sep=';', \n",
    "    usecols=['time', 'débit_insitu', 'débit_mgb'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )\n",
    "\n",
    "tamsat_daily_total = xr.load_dataset(DATA_PATH/\"tamsat_sub_poly_daily_total.nc\")\n",
    "\n",
    "data = pd.merge(df, tamsat_daily_total[\"rfe\"].to_dataframe(), left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col, y_col = [\"débit_mgb\", \"rfe\"], ['débit_insitu']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smooth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rfe\"] = smooth(data[\"rfe\"], window=58)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_scaler = RobustScaler()\n",
    "\n",
    "features = data[x_col]\n",
    "data[x_col] = features_scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "train_mask = df.index < '2019-01-01'\n",
    "\n",
    "train = data[train_mask]\n",
    "valid = data[~train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "predictions = []\n",
    "for degree in range(1, 4):\n",
    "    for window in range(10, 51, 10):\n",
    "        feature_generator = FeatureGenerator(context_window=window, target_window=10, degree=degree)        \n",
    "        train_x, train_y = feature_generator.generate(train, x_col, y_col)\n",
    "        valid_x, valid_y = feature_generator.generate(valid, x_col, y_col)\n",
    "\n",
    "        model = SimpleRegressionModel()\n",
    "        model.fit(train_x, train_y)\n",
    "        predictions.append(model.predict_as_dataframe(valid_x, degree=degree, ctx_window=window))\n",
    "\n",
    "\n",
    "predictions = pd.concat(predictions).reorder_levels(['degree', 'ctx_window', 'time']).to_xarray()\n",
    "observations = valid[y_col[0]].to_xarray().sel(time=slice(predictions.time.min(), predictions.time.max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_scores = BenchmarkScores()\n",
    "scores_ds = benchmark_scores.compute_scores(\n",
    "    predictions,\n",
    "    observations,\n",
    "    [\"mae\", \"rmse\", \"nse\", \"kge\"])\n",
    "best_scores = benchmark_scores.find_nbest_scores(\n",
    "    scores_ds,\n",
    "    how={\"mae\": \"min\", \"rmse\": \"min\", \"nse\": \"max\", \"kge\": \"max\"},\n",
    "    n=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_benchmark_scores(best_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis of the benchmark results shows the expected pattern of decreasing forecast accuracy as prediction horizons increase. In addition the closser the smoothing to 60 days the better the model works\n",
    "\n",
    "- Using a 7-day smoothing window for rainfall data, the model achieves optimal performance with polynomial features of degree 2 and context windows ranging from 40 to 50 timesteps in terms of MAE and RMSE. Howevers, NSE and KGE are optimal for linear models with wondow sizes of 20 to 50 depending on the forecast horizon.\n",
    "- Using a 15-day smoothing window for rainfall data, the model achieves optimal performance with polynomial features of degree 2 and context windows ranging from 30 to 50 timesteps in terms of MAE and RMSE. As before, linear models provide the bes NSE and KGE results\n",
    "- Using a 60-day smoothing window for rainfall data, the model achieves optimal performance with polynomial features of degree 2 and context window 10 in terms of MAE and RMSE. As before, linear models provide the bes NSE and KGE results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to be able to choose the best model we will analize three possibilities. \n",
    "- Average classic scores such as MAE and RMSE\n",
    "- Average Hydrological scores such as NSE and KGE\n",
    "- Average all the metrics scores. By this means we will normalize MAE and RMSE and inverse them being 1 the best and 0 the worst."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_average_score(scores, how=\"max\"):\n",
    "    \"\"\"Returns best model configuration based on averaged normalized scores across metrics.\"\"\"\n",
    "    metric_averaged_scores = scores.to_array().mean(dim=\"variable\")\n",
    "    \n",
    "    best_configuration = benchmark_scores.find_nbest_scores(\n",
    "        metric_averaged_scores.to_dataset(name=\"score\"), \n",
    "        how={\"score\": how}, \n",
    "        n=1\n",
    "    )\n",
    "    best_model_idx = {}\n",
    "    for idx, row in best_configuration.reset_index().iterrows():\n",
    "        best_model_idx[row[\"forecast_horizon\"]] = {\"degree\": row[\"degree\"], \"ctx_window\": row[\"ctx_window\"]}\n",
    "    return best_model_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now get the best models for classic scores and hydrological scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_classic = get_best_average_score(scores_ds[[\"mae\", \"rmse\"]], how=\"min\")\n",
    "best_model_hydro = get_best_average_score(scores_ds[[\"nse\", \"kge\"]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we will get the best models based on average score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def normalize_metrics(ds):\n",
    "    dims = [\"degree\", \"ctx_window\"]\n",
    "    return 1 - (ds - ds.min(dim=dims))/(ds.max(dim=dims) - ds.min(dim=dims))\n",
    "\n",
    "normalized_scores = scores_ds.copy()\n",
    "normalized_scores[[\"mae\", \"rmse\"]] = normalize_metrics(normalized_scores[[\"mae\", \"rmse\"]])\n",
    "best_model_avg = get_best_average_score(normalized_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now plot the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def plot_multimodel_discharge_comparison(\n",
    "        observed: xr.DataArray, # Time series of observed water discharge values\n",
    "        predicted: xr.Dataset, # Dataset containing predicted discharge values for each forecast horizon (t+i)\n",
    "        mgb: xr.DataArray, # Time series of MGB model water discharge predictions\n",
    "        best_model_classic: dict=None,\n",
    "        best_model_hydro: dict=None,\n",
    "        best_model_avg: dict=None\n",
    "        ) -> plt.Figure:\n",
    "    \"\"\"\n",
    "    Creates a multi-panel figure comparing observed discharge values with predictions from different models \n",
    "    (classic metrics, hydrological metrics, and averaged metrics) and MGB model predictions across multiple\n",
    "    forecast horizons.\n",
    "    \"\"\"\n",
    "    n_horizon = len(predicted.data_vars)\n",
    "    fig, axes = plt.subplots(int(n_horizon/2), 2, figsize=(20, int(n_horizon/2*5)), sharex=True, sharey=True)\n",
    "    axes = axes.flatten()\n",
    "\n",
    "    for i in range(0, n_horizon):\n",
    "        y_obs = observed.to_series()\n",
    "        y_mgb = mgb.to_series()\n",
    "        \n",
    "        # Plot observed and MGB\n",
    "        axes[i].plot(y_obs, label=\"Q_obs\", color='blue', linewidth=2)\n",
    "        axes[i].plot(y_mgb, label=\"Q_mgb\", color='black', linewidth=2)\n",
    "\n",
    "        # Plot predictions from different models\n",
    "        if best_model_classic is not None:\n",
    "            y_pred_classic = predicted[f\"t+{i+1}\"].sel(**best_model_classic[f\"t+{i+1}\"]).to_series()\n",
    "            axes[i].plot(y_pred_classic, label=\"Q_pred_classic\", color='red', linestyle='solid', linewidth=1.5)\n",
    "        \n",
    "        if best_model_hydro is not None:\n",
    "            y_pred_hydro = predicted[f\"t+{i+1}\"].sel(**best_model_hydro[f\"t+{i+1}\"]).to_series()\n",
    "            axes[i].plot(y_pred_hydro, label=\"Q_pred_hydro\", color='green', linestyle='solid', linewidth=1.5)\n",
    "        \n",
    "        if best_model_avg is not None:\n",
    "            y_pred_avg = predicted[f\"t+{i+1}\"].sel(**best_model_avg[f\"t+{i+1}\"]).to_series()\n",
    "            axes[i].plot(y_pred_avg, label=\"Q_pred_avg\", color='purple', linestyle='solid', linewidth=1.5)\n",
    "\n",
    "        axes[i].set_title(f\"Jour {i+1}\")\n",
    "        axes[i].grid(True, alpha=0.3)\n",
    "        axes[i].legend(loc='upper right')\n",
    "\n",
    "    plt.suptitle(\"Comparaison des valeurs réelles et prédites pour chaque jour de l'horizon de 10 jours\", fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plot_multimodel_discharge_comparison(\n",
    "    observed=observations, \n",
    "    predicted=predictions, \n",
    "    best_model_avg=best_model_avg,\n",
    "    best_model_classic=best_model_classic,\n",
    "    best_model_hydro=best_model_hydro,\n",
    "    mgb=df[~train_mask][\"débit_mgb\"].to_xarray(),\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The analysis reveals distinct patterns in model performance across different metrics. While the model optimized for hydrological scores shows unique behavior, the model selected based on classic metrics closely aligns with the averaged score model's predictions. This alignment may be attributed to similarities in how these scores are calculated.\n",
    "\n",
    "Based on our visual analysis, we observe two key patterns:\n",
    "\n",
    "- With a 15-day smoothing window, the best performing model varies depending on the forecast horizon, though it generally corresponds to the model with the highest averaged score\n",
    "- With a 60-day smoothing window, the model with the best averaged score consistently outperforms other models across all forecast horizons\n",
    "\n",
    "The visual inspection further validates that the 60-day smoothing window, which shows the strongest correlation with hydrological metrics, produces the most accurate predictions overall."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_scores = scores_ds.sel(degree=2, ctx_window=10).to_array(\"score\", name=\"scores\")#.rename({\"variable\": \"score\"})\n",
    "benchmark_results = xr.merge([predictions.sel(degree=2, ctx_window=10), observations, benchmark_scores])\n",
    "benchmark_results.to_netcdf(DATA_PATH/'tamsat_regression_benchmark.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
