{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TAMSAT Pertinence Analysis\n",
    "\n",
    "This notebook analyzes the relevance of TAMSAT (Tropical Applications of Meteorology using SATellite data) rainfall data for hydrological modeling in Senegal. It explores the relationship between TAMSAT precipitation estimates and river discharge measurements to assess the dataset's utility for flood forecasting and water resource management in the region.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp tamsat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from pathlib import Path\n",
    "import xarray as xr\n",
    "import geopandas as gpd\n",
    "import hvplot.pandas\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from ombs_senegal.region import get_region_mask\n",
    "\n",
    "\n",
    "DATA_PATH = Path(\"../../data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAMSAT Data preprocessing\n",
    "\n",
    "This section preprocesses TAMSAT rainfall data. First we will load and mask TAMSAT data over the region of interest\n",
    " \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import floor, ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roi_gdf = gpd.read_file(DATA_PATH/\"point_ajustement/sub4/sub4_senegal.shp\")\n",
    "bounds = roi_gdf.geometry.bounds\n",
    "min_lat, max_lat = bounds[\"miny\"].values, bounds[\"maxy\"].values\n",
    "min_lon, max_lon = bounds[\"minx\"].values, bounds[\"maxx\"].values\n",
    "\n",
    "tamsat = xr.open_dataset(DATA_PATH/\"01-tamsatDaily.v3.1-20100101-20250531-20250603_-16.85_-6.05_10.15_18.95.nc\")\n",
    "tamsat = tamsat.sel(lat=slice(floor(min_lat), ceil(max_lat), -1), lon=slice(floor(min_lon), ceil(max_lon)))\n",
    "mask = get_region_mask(tamsat, roi_gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "roi_tamsat = tamsat.where(mask)\n",
    "roi_tamsat = roi_tamsat.sel(time=slice(None, \"2024-12-31\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we're interested in the total rainfall across the basin rather than its spatial distribution, we'll sum up all rainfall values within the basin area. We'll save this aggregated data to avoid repeating the preprocessing steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "daily_total = roi_tamsat.sum([\"lat\", \"lon\"])\n",
    "daily_total.to_netcdf(DATA_PATH/\"tamsat_sub4_senegal_daily_total.nc\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TAMSAT estimate to in situ correlation\n",
    "\n",
    "We will analyze the correlation between TAMSAT rainfall estimates and observed river discharge (débit).\n",
    "To reduce noise and identify long-term patterns, we'll aggregate the data annually. This will help us:\n",
    "1. Evaluate how well TAMSAT rainfall estimates correspond to actual river flow\n",
    "2. Assess the potential effectiveness of using TAMSAT data in our benchmark model\n",
    "3. Account for seasonal patterns and lag effects between rainfall and discharge\n",
    "\n",
    "The correlation analysis will provide insights into whether TAMSAT data can be a reliable predictor for river discharge in our study area."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "insitu_df = pd.read_csv(\n",
    "    DATA_PATH/'data_cumul.csv', \n",
    "    sep=';', \n",
    "    usecols=['time', 'débit_insitu', 'P_mean'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tamsat_daily_total = xr.load_dataset(DATA_PATH/\"tamsat_sub4_senegal_daily_total.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "combined_df = pd.merge(insitu_df, tamsat_daily_total[\"rfe\"].to_dataframe(), left_index=True, right_index=True)\n",
    "yearly_df = combined_df.resample(\"YS\").sum()\n",
    "yearly_df = (yearly_df - yearly_df.min())/(yearly_df.max() - yearly_df.min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def r2(x, y):\n",
    "    res = x.sub(y).pow(2).sum()\n",
    "    tot = x.sub(x.mean()).pow(2).sum()\n",
    "    return 1 - res/tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2(yearly_df[\"débit_insitu\"], yearly_df[\"rfe\"]), r2(yearly_df[\"débit_insitu\"], yearly_df[\"P_mean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "plt.figure(figsize=(7,6))\n",
    "plt.scatter(yearly_df['débit_insitu'], yearly_df['rfe'])\n",
    "plt.scatter(yearly_df['débit_insitu'], yearly_df['P_mean'])\n",
    "\n",
    "# Add year labels to each point\n",
    "for idx, row in yearly_df.iterrows():\n",
    "    plt.annotate(idx.year, (row['débit_insitu'], row['rfe']), xytext=(5,5), textcoords='offset points')\n",
    "    plt.annotate(idx.year, (row['débit_insitu'], row['P_mean']), xytext=(5,5), textcoords='offset points')\n",
    "\n",
    "plt.xlabel('Débit in-situ')\n",
    "plt.ylabel('Rainfall Estimate (mm)')\n",
    "plt.title('Débit vs Rainfall')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As expected, in the above graph we can see that, even if there are some outliers such as 2020, there is a big correlation between the rainfall estimate and the river flow.\n",
    "\n",
    "We will now take a closer look by plotting the smoothed and normalized daily data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "from ombs_senegal.benchmark_model import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def smooth(df, window=7, missing_values=0):\n",
    "    smoothed_df = df.copy()\n",
    "    smoothed_df = smoothed_df.rolling(window=window).sum()\n",
    "    return smoothed_df.fillna(missing_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "processed_df = combined_df.copy()\n",
    "processed_df[\"rfe\"] = smooth(combined_df[\"rfe\"], window=60)\n",
    "normalized_df = normalize(processed_df)\n",
    "\n",
    "normalized_df.hvplot.line()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check cross correlation to determine the optimal smoothing window size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "\n",
    "# Calculate cross-correlation between rainfall and flow\n",
    "ccf_rfe = ccf(smooth(combined_df[\"rfe\"], window=30), combined_df['débit_insitu'], adjusted=False)\n",
    "#ccf_mgb = ccf(normalized_df['débit_mgb'], normalized_df['débit_insitu'], adjusted=False)\n",
    "\n",
    "# Plot cross-correlations\n",
    "plt.figure(figsize=(10,6))\n",
    "lags = range(len(ccf_rfe))\n",
    "plt.plot(lags, ccf_rfe, label='TAMSAT RFE vs In-situ Flow')\n",
    "#plt.plot(lags, ccf_mgb, label='MGB Flow vs In-situ Flow')\n",
    "plt.axhline(y=0, color='k', linestyle='--')\n",
    "plt.xlabel('Lag (days)')\n",
    "plt.ylabel('Cross-correlation')\n",
    "plt.title('Cross-correlation Analysis')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import signal\n",
    "from statsmodels.tsa.stattools import ccf\n",
    "import pandas as pd\n",
    "\n",
    "def find_optimal_window(rainfall, discharge, max_window=100, min_lag=0, max_lag=30):\n",
    "    \"\"\"\n",
    "    Find optimal smoothing window with constrained lag range\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    rainfall : array-like\n",
    "        Rainfall time series\n",
    "    discharge : array-like\n",
    "        Discharge time series\n",
    "    max_window : int\n",
    "        Maximum smoothing window to test\n",
    "    min_lag : int\n",
    "        Minimum lag to consider (typically 0 for rainfall-runoff)\n",
    "    max_lag : int\n",
    "        Maximum lag to consider (based on watershed characteristics)\n",
    "    \"\"\"\n",
    "    best_corr = -np.inf\n",
    "    best_window = 0\n",
    "    best_lag = 0\n",
    "    results = []\n",
    "    \n",
    "    for window in range(1, max_window + 1):\n",
    "        # Apply moving average to rainfall\n",
    "        smoothed_rain = smooth(rainfall, window=window)\n",
    "        \n",
    "        # Remove NaN values\n",
    "        valid_mask = ~np.isnan(smoothed_rain)\n",
    "        smooth_rain_clean = smoothed_rain[valid_mask]\n",
    "        discharge_clean = discharge[valid_mask]\n",
    "        \n",
    "        # Calculate cross correlation\n",
    "        ccf_result = ccf(smooth_rain_clean, discharge_clean)\n",
    "        \n",
    "        # Only consider the specified lag range\n",
    "        lag_range = slice(min_lag, max_lag + 1)\n",
    "        restricted_ccf = ccf_result[lag_range]\n",
    "        \n",
    "        max_corr = np.max(np.abs(restricted_ccf))\n",
    "        lag = np.argmax(np.abs(restricted_ccf)) + min_lag\n",
    "        \n",
    "        results.append({\n",
    "            'window': window,\n",
    "            'correlation': max_corr,\n",
    "            'lag': lag\n",
    "        })\n",
    "        \n",
    "        if max_corr > best_corr:\n",
    "            best_corr = max_corr\n",
    "            best_window = window\n",
    "            best_lag = lag\n",
    "            \n",
    "    return pd.DataFrame(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_correlations = find_optimal_window(combined_df['rfe'], combined_df['débit_insitu'])\n",
    "best_correlations.hvplot.line(x='window', y='correlation', hover_cols=['lag'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Benchmark with TAMSAT \n",
    "\n",
    "Based on the strong correlation observed between TAMSAT rainfall estimates and river flow, we will now evaluate the benchmark model using TAMSAT data. We will conduct two analyses:\n",
    "1. Using only TAMSAT rainfall estimates and MGB water flow predictions as input features\n",
    "2. Using all available parameters (TAMSAT rainfall, MGB flow, and other variables) as input features\n",
    "\n",
    "Similar to our previous analysis with IMERG data, we will:\n",
    "- Test different time window sizes to capture temporal patterns\n",
    "- Evaluate multiple polynomial degrees to model non-linear relationships\n",
    "- Compare model performance using standard metrics (MSE, MAE) and visual analysis\n",
    "\n",
    "This will allow us to:\n",
    "- Assess TAMSAT's effectiveness as a predictor\n",
    "- Compare results with the IMERG-based models\n",
    "- Determine optimal model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from ombs_senegal.benchmark_model import FeatureGenerator, SimpleRegressionModel\n",
    "from ombs_senegal.benchmark_model import plot_interactive_benchmark_scores, BenchmarkScores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "df = pd.read_csv(\n",
    "    DATA_PATH/'data_cumul.csv', \n",
    "    sep=';', \n",
    "    usecols=['time', 'P_cumul_7j', 'débit_insitu', 'débit_mgb'], \n",
    "    index_col='time',\n",
    "    converters={\"time\": pd.to_datetime}\n",
    "    )\n",
    "\n",
    "tamsat_daily_total = xr.load_dataset(DATA_PATH/\"tamsat_sub_poly_daily_total.nc\")\n",
    "\n",
    "data = pd.merge(df, tamsat_daily_total[\"rfe\"].to_dataframe(), left_index=True, right_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preprocess data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select feature and target columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col, y_col = [\"débit_mgb\", \"rfe\", \"P_cumul_7j\"], ['débit_insitu']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Smooth data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"rfe\"] = smooth(data[\"rfe\"], window=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "# Mise à l'échelle avec RobustScaler\n",
    "features_scaler = RobustScaler()\n",
    "\n",
    "features = data[x_col]\n",
    "data[x_col] = features_scaler.fit_transform(features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| skip_export\n",
    "train_mask = df.index < '2019-01-01'\n",
    "\n",
    "train = data[train_mask]\n",
    "valid = data[~train_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "predictions = []\n",
    "scores = []\n",
    "for degree in range(1, 4):\n",
    "    for window in range(10, 51, 10):\n",
    "        feature_generator = FeatureGenerator(context_window=window, target_window=10, degree=degree)        \n",
    "        train_x, train_y = feature_generator.generate(train, x_col, y_col)\n",
    "        valid_x, valid_y = feature_generator.generate(valid, x_col, y_col)\n",
    "\n",
    "        model = SimpleRegressionModel()\n",
    "        model.fit(train_x, train_y)\n",
    "        pred = model.predict(valid_x)\n",
    "\n",
    "        pred_df = pred.copy()\n",
    "        pred_df['degree'] = degree\n",
    "        pred_df['window'] = window\n",
    "        pred_df = pred_df.set_index(['degree', 'window'], append=True)\n",
    "        predictions.append(pred_df)\n",
    "\n",
    "predictions_ds = pd.concat(predictions).reorder_levels(['degree', 'window', 'time']).to_xarray()\n",
    "observations = valid[y_col].to_xarray().sel(time=slice(predictions_ds.time.min(), predictions_ds.time.max()))\n",
    "results_ds = predictions_ds.merge(observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "benchmark_scores = BenchmarkScores()\n",
    "scores_ds = benchmark_scores.compute_scores(predictions_ds.to_array(), observations[\"débit_insitu\"], [\"mae\", \"rmse\"])\n",
    "best_scores = benchmark_scores.find_nbest_scores(scores_ds, n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_interactive_benchmark_scores(best_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ombs_senegal.benchmark_model import plot_prediction_comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rescaled_features = pd.DataFrame(features_scaler.inverse_transform(valid[x_col]), index=valid.index, columns=x_col)\n",
    "debit_mgb = rescaled_features[\"débit_mgb\"].to_xarray()\n",
    "_ = plot_prediction_comparison(\n",
    "    observed=observations[\"débit_insitu\"],\n",
    "    predicted=predictions_ds.sel(degree=2, window=10),\n",
    "    mgb=debit_mgb,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#| eval: false\n",
    "benchmark_ds = results_ds.sel(degree=2, window=slice(30,50))\n",
    "benchmark_ds.to_netcdf(DATA_PATH/'tamsat_regression_benchmark.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
